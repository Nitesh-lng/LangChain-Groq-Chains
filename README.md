
# LangChain-Groq-Chains

This project demonstrates how to use [LangChain](https://www.langchain.com/) with the [Groq API](https://groq.com/) to build advanced language model pipelines using simple, sequential, parallel, and conditional execution strategies.

## ğŸš€ Features

- âœ… **Simple Chain**: Prompt â†’ LLM â†’ Output  
- ğŸ” **Sequential Chain**: Multi-step reasoning (Long â†’ Summary)
- ğŸ”„ **Parallel Chain**: Simultaneous generation of notes and quiz â†’ merged output
- âš–ï¸ **Conditional Chain**: Sentiment classification with branch logic

## ğŸ“‚ Project Structure

```
chains/
â”‚
â”œâ”€â”€ simple_chain.py              # Basic prompt chain using ChatGroq
â”œâ”€â”€ sequential_chain.py          # Multi-step sequential pipeline
â”œâ”€â”€ parellel_chain.py            # Parallel prompt processing & merging
â”œâ”€â”€ conditional_chain.py         # Branching logic using classification
â”œâ”€â”€ requirements.txt             # All required dependencies
â”œâ”€â”€ .env                         # Environment variables (add GROQ_API_KEY here)
```

## ğŸ§  LLMs Used

- `meta-llama/llama-4-scout-17b-16e-instruct`
- `deepseek-r1-distill-llama-70b`
- `llama3-8b-8192`

## ğŸ“¦ Requirements

Install dependencies using:

```bash
pip install -r requirements.txt
```

Your `.env` file should contain:

```
GROQ_API_KEY=your_groq_api_key
```

## â–¶ï¸ Usage

Run any chain file directly:

```bash
python simple_chain.py
python sequential_chain.py
python parellel_chain.py
python conditional_chain.py
```

## ğŸ“Œ Notes

- All LLMs are invoked via `langchain_groq.ChatGroq`
- Output parsing is handled with `StrOutputParser` and `PydanticOutputParser`
- Prompt templating is done via `PromptTemplate`

## ğŸ§‘â€ğŸ’» Author

**Nitesh Kumar Singh**  
*Data Scientist | AI Agent Systems | LLMs*

---

## ğŸ“ƒ License

This project is licensed under the MIT License.
